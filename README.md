# NumEdge

<div align="center">

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

**A lightweight, safety-first machine learning library built on NumPy**

*Making classical ML transparent, safe, and beginner-friendly*

[Installation](#-installation) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Features](#-what-makes-numedge-different) ‚Ä¢ [Documentation](#-documentation) ‚Ä¢ [Contributing](#-contributing)

</div>

---

## üéØ Why NumEdge?

Most machine learning libraries are either too simple for real work or too complex to understand. NumEdge bridges this gap.

**NumEdge is built for:**
- üéì **Students & Learners** ‚Äî Every algorithm is written in pure NumPy/Python. No hidden complexity, no black boxes.
- üõ°Ô∏è **Safety-Conscious Developers** ‚Äî Built-in warnings catch common ML mistakes before they become production bugs.
- üìä **Tabular Data Practitioners** ‚Äî First-class DataFrame support with automatic preprocessing.
- üî¨ **Research & Education** ‚Äî Clean, readable source code that teaches as much as it performs.

> **Philosophy:** Readable over fast. Understanding over optimization. Safety over convenience.

---

## ‚ú® What Makes NumEdge Different?

### 1Ô∏è‚É£ **Transparent by Design**
Every algorithm implemented in pure NumPy and Python. Open the source, understand the math, learn how ML actually works.

### 2Ô∏è‚É£ **Safety-First Approach**
NumEdge actively protects you from common mistakes:
- ‚ö†Ô∏è Warns when evaluating on training data
- ‚ö†Ô∏è Detects missing `random_state` for reproducibility
- ‚ö†Ô∏è Catches shape mismatches and data leakage patterns
- ‚ö†Ô∏è Validates preprocessing pipelines

### 3Ô∏è‚É£ **Tabular-First Design**
Real-world data comes in CSVs with mixed types. NumEdge handles this automatically:

```python
from numedge.tabular import TabularClassifier
from numedge.models.ensemble import RandomForestClassifier

# Just pass your DataFrame ‚Äî NumEdge handles the rest
model = TabularClassifier(
    estimator=RandomForestClassifier(),
    target="label"
)

model.fit(df_train)  # Auto-detects numeric/categorical columns
predictions = model.predict(df_test)  # Auto-preprocesses test data
```

### 4Ô∏è‚É£ **Built-in Hyperparameter Intelligence**
Every model knows its own optimal search spaces:

```python
model = RandomForestClassifier()
search_space = model.get_search_space()  # Recommended ranges for tuning
# {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 20, None], ...}
```

### 5Ô∏è‚É£ **Streaming-Friendly**
Supports incremental learning where it makes sense:

```python
model = LinearRegression()
for batch in data_stream:
    model.partial_fit(X_batch, y_batch)  # Learn incrementally
```

---

## üöÄ Installation

### Requirements
- Python 3.8 or higher
- NumPy (required)
- pandas (optional, for tabular features)

### Install from Source

```bash
git clone https://github.com/Nitin-Prata/numedge.git
cd numedge
pip install -e .
```

> **Coming soon to PyPI:** `pip install numedge`

---

## üîß Quick Start

### Basic Regression

```python
from numedge.models.linear_models import LinearRegression
from numedge.model_selection import train_test_split

# Split your data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Train
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
predictions = model.predict(X_test)

# Evaluate
score = model.score(X_test, y_test)
print(f"R¬≤ Score: {score:.3f}")
```

### Classification with Safety Checks

```python
from numedge.models.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# NumEdge warns you if you accidentally evaluate on training data
train_score = model.score(X_train, y_train)  # ‚ö†Ô∏è Warning: Evaluating on training data!
test_score = model.score(X_test, y_test)     # ‚úì Correct evaluation
```

### Tabular Data with DataFrames

```python
from numedge.tabular import TabularRegressor
from numedge.models.ensemble import GradientBoostingRegressor

# Your DataFrame has mixed types: numeric, categorical, dates, etc.
model = TabularRegressor(
    estimator=GradientBoostingRegressor(),
    target="price"
)

# NumEdge automatically:
# - Detects column types
# - Scales numeric features
# - Encodes categorical features
# - Handles missing values
model.fit(df_train)

predictions = model.predict(df_test)
```

---

## üß† Algorithms

### Supervised Learning

**Linear Models**
- Linear Regression
- Ridge Regression
- Lasso Regression
- Elastic Net
- Logistic Regression

**Tree-Based Models**
- Decision Trees (Classifier & Regressor)
- Random Forest (Classifier & Regressor)
- Extra Trees
- Gradient Boosting
- AdaBoost
- Bagging

**Support Vector Machines**
- SVM Classifier
- SVM Regressor

**Neighbors**
- KNN Classifier
- KNN Regressor

**Naive Bayes**
- Gaussian Naive Bayes
- Multinomial Naive Bayes

**Boosting**
- NumPy-based XGBoost implementation

### Unsupervised Learning

**Clustering**
- K-Means
- DBSCAN
- Hierarchical Clustering

**Dimensionality Reduction**
- PCA (Principal Component Analysis)

### Preprocessing
- Standard Scaler
- Min-Max Scaler
- One-Hot Encoder
- Label Encoder

### Model Selection
- Train-Test Split
- Cross-Validation
- Hyperparameter Search

---

## üìÅ Project Structure

```
numedge/
‚îú‚îÄ‚îÄ src/numedge/
‚îÇ   ‚îú‚îÄ‚îÄ core/              # BaseEstimator, mixins, optimizers, exceptions
‚îÇ   ‚îú‚îÄ‚îÄ models/            # All supervised learning algorithms
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear_models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ensemble/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tree/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ svm/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ neighbors/
‚îÇ   ‚îú‚îÄ‚îÄ cluster/           # Clustering algorithms
‚îÇ   ‚îú‚îÄ‚îÄ decomposition/     # PCA and dimensionality reduction
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/     # Scalers, encoders, transformers
‚îÇ   ‚îú‚îÄ‚îÄ model_selection/   # Cross-validation, search utilities
‚îÇ   ‚îú‚îÄ‚îÄ metrics/           # Evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ tabular/           # DataFrame-friendly helpers
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Internal utilities and validators
‚îú‚îÄ‚îÄ tests/                 # Comprehensive unit tests
‚îú‚îÄ‚îÄ examples/              # Usage examples and tutorials
‚îî‚îÄ‚îÄ docs/                  # Documentation (coming soon)
```

---

## üéì Learning Resources

NumEdge is designed to be educational. Each algorithm includes:
- üìñ Clear docstrings explaining the math
- üîç Readable source code with extensive comments
- ‚úÖ Type hints for better IDE support
- üß™ Unit tests showing expected behavior

**Recommended Learning Path:**
1. Start with `LinearRegression` ‚Äî see how gradient descent works
2. Move to `DecisionTree` ‚Äî understand recursive splitting
3. Explore `RandomForest` ‚Äî see how ensemble methods combine weak learners
4. Deep dive into `GradientBoosting` ‚Äî learn advanced boosting

---

## üìö Documentation

Full documentation is in development and will cover:
- üìò API Reference
- üèóÔ∏è Architecture & Design Decisions
- üìù Tutorials & Examples
- üßë‚Äçüè´ Algorithm Explanations
- ü§ù Contribution Guide

---

## ü§ù Contributing

NumEdge is actively developed and welcomes contributions!

**Ways to contribute:**
- üêõ Report bugs and issues
- üí° Suggest new features or algorithms
- üìñ Improve documentation
- ‚ú® Submit pull requests
- ‚≠ê Star the repository

Please check our [Contributing Guidelines](CONTRIBUTING.md) before submitting PRs.

---

## üõ£Ô∏è Roadmap

- [ ] Complete test coverage (>90%)
- [ ] Comprehensive documentation site
- [ ] PyPI release
- [ ] Additional algorithms (LightGBM-style, CatBoost-style)
- [ ] Performance benchmarks
- [ ] Interactive tutorials and notebooks
- [ ] CI/CD pipeline
- [ ] GPU acceleration (optional)

---

## üìÑ License

NumEdge is released under the [MIT License](LICENSE).

---

## üë®‚Äçüíª Author

**Nitin Pratap Singh**

- GitHub: [@Nitin-Prata](https://github.com/Nitin-Prata)
- LinkedIn: [Nitin Singh](https://www.linkedin.com/in/nitin-singh-bb7907298/)
- X (Twitter): [@prata42085](https://x.com/prata42085)
- Email: nitinpratap997@gmail.com

---

## üôè Acknowledgments

NumEdge is inspired by the need for transparent, educational machine learning tools. While it shares API conventions with popular libraries, it maintains its own identity focused on clarity, safety, and learning.

Special thanks to the open-source ML community for creating an ecosystem that makes projects like this possible.

---

## ‚≠ê Star History

If you find NumEdge useful, please consider starring the repository!

[![Star History Chart](https://api.star-history.com/svg?repos=Nitin-Prata/numedge&type=Date)](https://star-history.com/#Nitin-Prata/numedge&Date)

---

<div align="center">

**Made with ‚ù§Ô∏è for the ML community**

[Report Bug](https://github.com/Nitin-Prata/numedge/issues) ‚Ä¢ [Request Feature](https://github.com/Nitin-Prata/numedge/issues) ‚Ä¢ [Ask Question](https://github.com/Nitin-Prata/numedge/discussions)

</div>